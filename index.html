<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>
<head>
<title>CIS 607: Deep Learning for Natural Language Processing | University of Oregon</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link href="./styles/bootstrap.min.css" rel="stylesheet" type="text/css" media="screen" />
<link href="./styles/style.css" rel="stylesheet" type="text/css" media="screen" />
<style>
.hw { color: red }		
.hw a { color: red }		
</style>
</head>
<body bgcolor=#6D7B8D align="justify">
<div id="container">
<div id="content">
<h1 align="center">CIS 607: Seminar on Deep Learning for Natural Language Processing</h1> <hr>


<h3>Course Description</h3> 

Deep learning has recently proved itself as a powerful branch of machine learning that has applications in a variety of domains (i.e., computer vision, robotics, etc.). 
In natural language processing (NLP), deep learning has been transformative and led to a new generation of methods with better performance, portability and robustness (e.g, the machine translation systems). 
All of those advances are very recent and the demand for data scientists with deep learning expertise is growing very quickly.

At the beginning of this seminar, we will cover the basic concepts of deep learning and NLP, and possibly provide some hand-on experience to implement the models. 
Afterward, we will review and discuss a collection of research papers on NLP with deep learning, including but not limited to the typical tasks of question answering, information extraction, natural language inference, dialog and summarization. 
<br/><br/>

	<b>Prerequisites:</b> Some background in algebra and machine learning (i.e., CIS 472/572). Please talk with the instructor if you are not sure if you have the necessary background.<br/><br/>

	<b>Class Location:</b> 200 Deschutes Hall<br/><br/>

	<b>Class Time:</b> Friday, 14:30 pm to 15:50 pm </br></br>

	<b>Instructor:</b> <a href="http://ix.cs.uoregon.edu/~thien">Thien Huu Nguyen</a><br/>
	Email: thien AT cs.uoregon.edu <br/>
	Office: Room 330, Deschutes Hall <br/><br/>
	
	<b>Course Material:</b>
	<br/>
	Goldberg. <a href="https://www.morganclaypool.com/doi/abs/10.2200/S00762ED1V01Y201703HLT037">Neural Network Methods for Natural Language Processing</a> 2017. (free download when on UO campus).
	</br>
	<a href="https://github.com/nyu-dl/NLP_DL_Lecture_Note/blob/master/lecture_note.pdf">Kyunghyun Cho's note</a>
	</br>
	<a href="https://aclanthology.coli.uni-saarland.de/">ACL Anthology</a> (free and covering the papers in most of the major NLP venues)
	
	</br></br>
	<b>Class Organization</b></br>
	The grading for this class is P/NP. </br>
	
	Each student in the class will need to choose some paper on some particular topic, present them in one of the classes and lead the discussion on the topic. </br>
	Each presentation will be given 30 minutes along with 5-10 minutes for discussions. More discussion is encouraged on <a href="https://piazza.com/uoregon/winter2019/cis607semdl4nlp">Piazza</a>. </br>
	After the presentation, the presenter needs to submit a summary about the presented paper/topic. The summary should follow the <a href="http://naacl.org/naacl-pubs/">NAACL</a> format (a.k.a. ACL style for 8.5x11 paper). The required length of the summary is between 2 and 3 pages. </br>
	For each presentation, we will have one student (other than the presenter) to serve as the reviewer. The role of the reviewer is to provide judgement/comments/suggestion or ask questions about the paper/topic in the discussion time after the presentation.
	Although all students need to read and understand the papers being presented before each class to be able to actively contribute to the discussions, the reviewer would help to provide deeper judgement by reading and thinking critically about the papers/topics ahead of time. </br>
	
	<h4> IMPORTANT:</h4> Please select a paper you want to present in <a href="https://docs.google.com/spreadsheets/d/1ccjKhDifpV1K__ml85beiIzRtGpMf6MnbOCwtW0L5ko/edit?usp=sharing">this list</a>. Write your name next to the paper you select.
You are welcome to choose another paper that is not in the list. Please talk with the instructor if you want to do this.
Also, please provide the ID of the paper/topic you want to review next to your name.
All the paper assignments should be done before Jan 22 (no later than that) so we can schedule the presentations.

	
	</br></br>

	<h3>Tentative Schedule</h3>
	Please sign up on <a href="https://piazza.com/uoregon/winter2019/cis607semdl4nlp">Piazza</a> for discussions.
	
	<table class="tg">
	<tr>
	<th>Week</th>
	<th>Topics</th>
	<th>Presenter</th>
	<th>Slides</th>
	<th>Reviewer</th>
    </tr>

	<tr>
	<th>01/11</th>
	<td><a href="notes/cis607week1.pdf">Introduction, Basic Concepts in NLP and Deep Learning</a></td>
	<td>Thien</td>
	<td><a href="notes/cis607week1.pdf">Link</a></td>
	<td></td>
	</tr>
	
	<tr>
	<th rowspan="2">01/18</th>
	<td>
	<a href="http://www.aclweb.org/anthology/P18-1234">Sentiment Analysis: Aspect Based Sentiment Analysis with Gated Convolutional Networks</a>
	</td>
	<td>
	Amir Veyseh
	</td>
	<td>
	<a href="notes/Amir.pdf">Link</a>
	</td>
	<td>
	Viet Lai
	</td>
	</tr>
	<tr>
	<td>
	<a href="https://arxiv.org/abs/1802.05365">Deep contextualized word representations</a>
	</td>
	<td>
	Viet Lai
	</td>
	<td></td>
	<td>
	Amir Veyseh
	</td>
	</tr>
	
	<tr>
	<th rowspan="2">01/25</th>
	<td>
	<a href="https://arxiv.org/abs/1607.01759">Text Classification: Bag of Tricks for Efficient Text Classification</a>
	</td>
	<td>
	Ziyad Alsaeed
	</td>
	<td>
	<a href="notes/Ziyad.pdf">Link</a>
	</td>
	<td>
	Zayd Hammoudeh
	</td>
	</tr>
	<tr>
	<td>
	<a href="http://aclweb.org/anthology/P17-1152">Natural Language Inference: Enhanced LSTM for Natural Language Inference</a>
	</td>
	<td>
	Roscoe Casita
	</td>
	<td>
	<a href="notes/Roscoe.pdf">Link</a>
	</td>
	<td>
	Luis Guzman
	</td>
	</tr>
	
	<tr>
	<th>02/01</th>
	<td>
	No Class (AAAI 2019)
	</td>
	<td>
	<td></td>
	</td>
	<td>
	</td>
	</tr>
	
	<tr>
	<th rowspan="2">02/08</th>
	<td>
	<a href="http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf">Language Modeling: RNN for Language Models</a>
	</td>
	<td>
	Qiuhao Lu
	</td>
	<td>
	<a href="notes/Qiuhao.pdf">Link</a>
	</td>
	<td>
	Luke Strgar
	</td>
	</tr>
	<tr>
	<td>
	<a href="https://arxiv.org/pdf/1506.03340.pdf">Question Answering: Teaching Machines to Read and Comprehend</a>
	</td>
	<td>
	Shiloh Deitz
	</td>
	<td>
	<a href="notes/Shiloh.pdf">Link</a>
	</td>
	<td>
	Trevor Bergstrom
	</td>
	</tr>
	
	<tr>
	<th rowspan="2">02/15</th>
	<td>
	<a href="https://arxiv.org/abs/1409.0473">Machine Translation: Neural Machine Translation by Jointly Learning to Align and Translate</a>
	</td>
	<td>
	Antoine Nzeyimana
	</td>
	<td>
	<a href="notes/Antoine.pdf">Link</a>
	</td>
	<td>
	Ziyad Alsaeed
	</td>
	</tr>
	<tr>
	<td>
	<a href="https://arxiv.org/abs/1509.00685">Summarization: A Neural Attention Model for Abstractive Sentence Summarization</a>
	</td>
	<td>
	Peter Lovett
	</td>
	<td>
	<a href="notes/Peter.pdf">Link</a>
	</td>
	<td>
	Shiloh Deitz
	</td>
	</tr>
	
	<tr>
	<th rowspan="2">02/22</th>
	<td>
	<a href="https://arxiv.org/abs/1705.02364">Supervised sentence representation: Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</a>
	</td>
	<td>
	Adam Noack
	</td>
	<td>
	<a href="https://docs.google.com/presentation/d/15Ir5xJzVOK_zulEpR2duVllr8rK7561wGYR3RVNPIY4/edit?ts=5c76e049#slide=id.p">Link</a>
	</td>
	<td>
	Antoine Nzeyimana
	</td>
	</tr>
	<tr>
	<td>
	<a href="http://markyatskar.com//publications/bias.pdf">Bias in NLP: Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints</a>
	</td>
	<td>
	Trevor Bergstrom
	</td>
	<td>
	<a href="notes/Trevor.pdf">Link</a>
	</td>
	<td>
	Adib Mosharrof
	</td>
	</tr>
	
	<tr>
	<th rowspan="2">03/01</th>
	<td>
	<a href="http://aclweb.org/anthology/D18-1226">Domain Adaptation: Neural Adaptation Layers for Cross-domain Named Entity Recognition</a>
	</td>
	<td>
	Adib Mosharrof
	</td>
	<td></td>
	<td>
	Adam Noack
	</td>
	</tr>
	<tr>
	<td>
	<a href="https://arxiv.org/pdf/1511.02799.pdf">Visual Question Answering: Deep Compositional Question Answering with Neural Module Networks</a>
	</td>
	<td>
	Luis Guzman
	</td>
	<td>
	<a href="notes/Luis.pdf">Link</a>
	</td>
	<td>
	Qiuhao Lu
	</td>
	</tr>
	
	<tr>
	<th rowspan="2">03/08</th>
	<td>
	<a href="http://aclweb.org/anthology/D18-1020">Variational Auto-Encoder and Semi-supervised learning: Variational Sequential Labelers for Semi-Supervised Learning</a>
	</td>
	<td>
	Zayd Hammoudeh
	</td>
	<td>
	<a href="notes/Zayd.pdf">Link</a>
	</td>
	<td>
	Roscoe Casita
	</td>
	</tr>
	<tr>
	<td>
	<a href="https://www.aclweb.org/anthology/W/W17/W17-2629.pdf">GAN for text generation: Adversarial Generation of Natural Language</a>
	</td>
	<td>
	Luke Strgar
	</td>
	<td></td>
	<td>
	Peter Lovett
	</td>
	</tr>
    
	</table>
	

	</div>
	</body>
	</html>